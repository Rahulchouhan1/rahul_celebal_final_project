# ğŸš€ Azure Data Factory Conditional ETL Pipeline â€“ Customer & Product Data

## ğŸ“Œ Problem Statement

Design a dynamic and conditional data pipeline in **Azure Data Factory** that:

1. Copies **Customer data** from a database to **Azure Data Lake Storage (ADLS)** only if the number of customer records is **greater than 500**.
2. If the condition is met, the pipeline should trigger a **child pipeline** that copies **Product data** from the database to ADLS, but **only if the customer count is greater than 600**.
3. The customer count should be passed from the parent to the child pipeline using **pipeline parameters**.

---

## ğŸ§  Logic & Design Thinking

To build this efficiently and scalably, the following architectural design was applied:

- **Parent Pipeline** handles:
  - Fetching the customer count from a source table
  - Evaluating if the count is greater than 500
  - Copying Customer data conditionally
  - Triggering a **child pipeline** and passing the count

- **Child Pipeline**:
  - Accepts `customerCount` as a parameter
  - Copies Product data **only** if `customerCount > 600`

- All data is saved to **Azure Data Lake Gen2** in folders for downstream use.

### ğŸ§± Key Components Used:
- **Lookup Activity** â€“ to get customer count
- **Set Variable** â€“ to store count
- **If Condition** â€“ to apply logic (> 500 and > 600)
- **Copy Data** â€“ to perform actual ETL
- **Execute Pipeline** â€“ to call child pipeline
- **Pipeline Parameters** â€“ to pass values between pipelines

---

## ğŸ—ï¸ Step-by-Step Pipeline Creation

### ğŸ”· Step 1: Create the Parent Pipeline (`CopyCustomerData_Pipeline`)
1. **Lookup Activity**:  
   Query: `SELECT COUNT(*) as totalCount FROM Customer`
2. **Set Variable**:  
   Save the count from lookup:  
   `@activity('GetCustomerCount').output.firstRow.totalCount`
3. **If Condition (CustomerCount > 500)**:  
   Expression:
   ```expression
   @greater(variables('CustomerCount'), 500)
Inside True block:

âœ… Add Copy Data â†’ Copy Customer table to ADLS

âœ… Add Execute Pipeline â†’ Call ChildPipeline_ProductCopy

Pass parameter:

expression
Copy
Edit
@variables('CustomerCount')
ğŸ”· Step 2: Create the Child Pipeline (ChildPipeline_ProductCopy)
Add a pipeline parameter: customerCount (Int)

If Condition (CustomerCount > 600):
Expression:

expression
Copy
Edit
@greater(int(pipeline().parameters.customerCount), 600)
Inside True block:

âœ… Add Copy Data â†’ Copy Product table to ADLS

ğŸ”· Step 3: Export and Deploy
Export ARM templates via Manage > ARM Template > Export

Upload to GitHub under /arm_templates/

âœ… Sample Output (from Debug)
ğŸŸ¢ Parent Pipeline
Customer Count: 1000

CopyCustomerData â†’ Succeeded (1000 rows copied)

ExecutePipeline â†’ Child called successfully

ğŸŸ¢ Child Pipeline
Parameter received: customerCount = 1000

Condition > 600 â†’ true

CopyProductData â†’ Succeeded (1000 rows copied)

ğŸ“‚ Project Structure
pgsql
Copy
Edit
ADF-Customer-Product-Pipeline/
â”œâ”€â”€ arm_templates/
â”‚   â”œâ”€â”€ factory/
â”‚   â”œâ”€â”€ linkedTemplates/
â”‚   â”œâ”€â”€ ARMTemplateForFactory.json
â”‚   â””â”€â”€ ARMTemplateParametersForFactory.json
â”œâ”€â”€ sample_data/
â”‚   â””â”€â”€ mock_customer_data.csv
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ pipeline_flow.png
â”‚   â””â”€â”€ output_success.png
â””â”€â”€ README.md
ğŸ§ª How to Use
Import ARM templates into your ADF instance

Configure linked services (SQL + ADLS)

Trigger the parent pipeline

Check Monitor tab for debug results

ğŸ“ˆ Future Enhancements
Add logging to ADLS or SQL audit table

Add email/SMS alerts on failure

Add dynamic file naming (utcnow() or GUID-based)

Parameterize DB and ADLS paths for reusability

ğŸ”— Author & Links
ğŸ‘¨â€ğŸ’» Built by Rahul Singh Chouhan

 
